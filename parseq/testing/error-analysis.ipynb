{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis of PARSeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from editdistance import eval as edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gt</th>\n",
       "      <th>pred</th>\n",
       "      <th>confidence</th>\n",
       "      <th>confidence_string</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'/Dataset/modern/Google_books/images/I1KG1259...</td>\n",
       "      <td>པའི་རྩ་བ་ཉམས་པ།བླ་མ་དང་མཆེད་གྲོགས་ལ་དམ་ཚིག་ཉམས་པ་</td>\n",
       "      <td>པའི་རྩ་བ་ཉམས་པ།བླ་མ་དང་མཆེད་གྲོགས་ལ་དམ་ཚིག་ཉམས་པ་</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'/Dataset/modern/Google_books/images/I2PD1835...</td>\n",
       "      <td>སྐྱིད།པོ་ནི་བོད་ཡུལ་མུན་སེལ་གཅིག་པོ་ཡོང་བའི་པོ...</td>\n",
       "      <td>སྐྱིད།པོ་ནི་བོད་ཡུལ་མུན་སེལ་གཅིག་པོ་ཡོང་བའི་པོ...</td>\n",
       "      <td>0.995991</td>\n",
       "      <td>tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'/Dataset/modern/Google_books/images/I1KG1259...</td>\n",
       "      <td>གོས་མེད་གཅེར་བུར་འཁྱགས་སྦུབས་རླུང་མི་བཟད་པས་ཉེ...</td>\n",
       "      <td>གོས་མེད་གཅེར་བུར་འཁྱགས་སྦུབས་རླུང་མི་བཟད་པས་ཉེ...</td>\n",
       "      <td>0.896090</td>\n",
       "      <td>tensor([1.0000, 0.9999, 1.0000, 1.0000, 1.0000...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'/Dataset/modern/Google_books/images/I1KG1259...</td>\n",
       "      <td>།བསམ་མི་ཁྱབ་</td>\n",
       "      <td>།བསམ་མི་ཁྱབ་</td>\n",
       "      <td>0.974782</td>\n",
       "      <td>tensor([0.9963, 0.9888, 0.9998, 1.0000, 1.0000...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'/Dataset/modern/Google_books/images/I1KG1260...</td>\n",
       "      <td>དབང་པོ་གང་དང་གང་ལམ་ཉིད།།</td>\n",
       "      <td>དབང་པོ་གང་དང་གང་ལམ་ཉིད།།</td>\n",
       "      <td>0.974970</td>\n",
       "      <td>tensor([1.0000, 1.0000, 1.0000, 0.9999, 1.0000...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  b'/Dataset/modern/Google_books/images/I1KG1259...   \n",
       "1  b'/Dataset/modern/Google_books/images/I2PD1835...   \n",
       "2  b'/Dataset/modern/Google_books/images/I1KG1259...   \n",
       "3  b'/Dataset/modern/Google_books/images/I1KG1259...   \n",
       "4  b'/Dataset/modern/Google_books/images/I1KG1260...   \n",
       "\n",
       "                                                  gt  \\\n",
       "0  པའི་རྩ་བ་ཉམས་པ།བླ་མ་དང་མཆེད་གྲོགས་ལ་དམ་ཚིག་ཉམས་པ་   \n",
       "1  སྐྱིད།པོ་ནི་བོད་ཡུལ་མུན་སེལ་གཅིག་པོ་ཡོང་བའི་པོ...   \n",
       "2  གོས་མེད་གཅེར་བུར་འཁྱགས་སྦུབས་རླུང་མི་བཟད་པས་ཉེ...   \n",
       "3                                       །བསམ་མི་ཁྱབ་   \n",
       "4                           དབང་པོ་གང་དང་གང་ལམ་ཉིད།།   \n",
       "\n",
       "                                                pred  confidence  \\\n",
       "0  པའི་རྩ་བ་ཉམས་པ།བླ་མ་དང་མཆེད་གྲོགས་ལ་དམ་ཚིག་ཉམས་པ་    0.724866   \n",
       "1  སྐྱིད།པོ་ནི་བོད་ཡུལ་མུན་སེལ་གཅིག་པོ་ཡོང་བའི་པོ...    0.995991   \n",
       "2  གོས་མེད་གཅེར་བུར་འཁྱགས་སྦུབས་རླུང་མི་བཟད་པས་ཉེ...    0.896090   \n",
       "3                                       །བསམ་མི་ཁྱབ་    0.974782   \n",
       "4                           དབང་པོ་གང་དང་གང་ལམ་ཉིད།།    0.974970   \n",
       "\n",
       "                                   confidence_string  correct  \n",
       "0  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000...     True  \n",
       "1  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000...     True  \n",
       "2  tensor([1.0000, 0.9999, 1.0000, 1.0000, 1.0000...     True  \n",
       "3  tensor([0.9963, 0.9888, 0.9998, 1.0000, 1.0000...     True  \n",
       "4  tensor([1.0000, 1.0000, 1.0000, 0.9999, 1.0000...     True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./output_with_conf.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows:  245790\n",
      "Total correct:  200935\n",
      "Total incorrect:  44855\n",
      "Accuracy:  0.817506814760568\n"
     ]
    }
   ],
   "source": [
    "print('Total rows: ', len(df))\n",
    "print('Total correct: ', len(df[df['correct'] == True]))\n",
    "print('Total incorrect: ', len(df[df['correct'] == False]))\n",
    "print('Accuracy: ', len(df[df['correct'] == True]) / len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "confidence_threshold_buckets = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# ... existing code until the Excel writing part ...\n",
    "for i in range(len(confidence_threshold_buckets)-1):\n",
    "    th1 = confidence_threshold_buckets[i]\n",
    "    th2 = confidence_threshold_buckets[i+1]\n",
    "    # incorrect_df is df[df['confidence'] > th1] and df[df['confidence'] < th2]\n",
    "    incorrect_df = df[(df['confidence'] > th1) & (df['confidence'] < th2)]\n",
    "    incorrect_df = incorrect_df[incorrect_df['confidence'] < th2]\n",
    "    incorrect_df = incorrect_df[incorrect_df['correct'] == False]\n",
    "    # pick max(50, len(incorrect_df))\n",
    "    incorrect_df = incorrect_df.head(min(50, len(incorrect_df)))\n",
    "    with pd.ExcelWriter(\n",
    "        f'./visualized/visual_analysis_{th1}.xlsx', \n",
    "        engine='xlsxwriter'\n",
    "    ) as writer:\n",
    "        workbook = writer.book\n",
    "        worksheet = workbook.add_worksheet('Analysis')\n",
    "        \n",
    "        # Set column widths\n",
    "        worksheet.set_column('A:A', 50)  # Image column\n",
    "        worksheet.set_column('B:D', 20)  # Other columns\n",
    "        \n",
    "        # Write headers\n",
    "        headers = ['Image', 'Ground Truth', 'Prediction', 'Confidence', 'Edit Distance', 'Label Length']\n",
    "        for col, header in enumerate(headers):\n",
    "            worksheet.write(0, col, header)\n",
    "        \n",
    "        row = 1\n",
    "        for index, row_data in incorrect_df.iterrows():\n",
    "            path, gt, pred, conf = row_data['path'], row_data['gt'], row_data['pred'], row_data['confidence']\n",
    "            path = path.replace('b\\'', '').replace('\\'', '')\n",
    "            img_name = path.split('/')[-1]\n",
    "            path = os.path.join('/Dataset/monlam-data/monlam.ai.ocr/OCR/training_images/', img_name)\n",
    "            edit_d = edit_distance(gt, pred)\n",
    "            label_len = len(gt)\n",
    "            # Read and process image\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, (512, 32))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            \n",
    "            # Save image to memory buffer\n",
    "            image_buffer = BytesIO()\n",
    "            Image.fromarray(img).save(image_buffer, format='PNG')\n",
    "            \n",
    "            # Insert image into worksheet\n",
    "            worksheet.insert_image(row, 0, '', {'image_data': image_buffer})\n",
    "            worksheet.set_row(row, 40)  # Set row height to accommodate image\n",
    "            \n",
    "            # Write other data\n",
    "            worksheet.write(row, 1, gt)\n",
    "            worksheet.write(row, 2, pred)\n",
    "            worksheet.write(row, 3, float(conf))\n",
    "            worksheet.write(row, 4, edit_d)\n",
    "            worksheet.write(row, 5, label_len)\n",
    "            \n",
    "            row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Distance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Edit distance = minimum( insertion, deletion, replacements)\n",
    "While computing edit distance let’s track the most optimal path and note down the frequency insertions, deletions and replacements for each character. \n",
    "\"\"\"\n",
    "# import edit distance from editdistance\n",
    "import editdistance\n",
    "import pandas as pd\n",
    "\n",
    "insertions = {}\n",
    "deletions = {}\n",
    "replacements = {}\n",
    "\n",
    "def edit_distance_dp(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    \n",
    "    dp = [[0] * (len(s2) + 1) for _ in range(len(s1) + 1)]\n",
    "    path = [[None] * (len(s2) + 1) for _ in range(len(s1) + 1)]\n",
    "    for i in range(len(s1) + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len(s2) + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, len(s1) + 1):\n",
    "        for j in range(1, len(s2) + 1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "                path[i][j] = (i-1, j-1)\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1\n",
    "                # here dp[i-1][j] is deletion, dp[i][j-1] is insertion, dp[i-1][j-1] is replacement\n",
    "                if dp[i][j] == dp[i-1][j] + 1:\n",
    "                    path[i][j] = (i-1, j)\n",
    "                elif dp[i][j] == dp[i][j-1] + 1:\n",
    "                    path[i][j] = (i, j-1)\n",
    "                else:\n",
    "                    path[i][j] = (i-1, j-1)\n",
    "            \n",
    "        # backtrack to get the path\n",
    "        i, j = len(s1), len(s2)\n",
    "        while path[i][j] is not None:\n",
    "            prev = path[i][j]\n",
    "            if prev[0] == i-1 and prev[1] == j-1 and s1[i-1] != s2[j-1]:\n",
    "                replacement_pair = (s1[i-1], s2[j-1])\n",
    "                replacements[replacement_pair] = replacements.get(replacement_pair, 0) + 1\n",
    "            elif prev[0] == i-1 and prev[1] == j:\n",
    "                deletions[s1[i-1]] = deletions.get(s1[i-1], 0) + 1\n",
    "            elif prev[0] == i and prev[1] == j-1:\n",
    "                insertions[s2[j-1]] = insertions.get(s2[j-1], 0) + 1\n",
    "            i, j = prev\n",
    "    return dp[-1][-1]\n",
    "\n",
    "\n",
    "output_df = pd.read_csv('./output_with_conf.csv')\n",
    "\n",
    "# apply edit distance dp to gt and pred, but remove these two chars before computing edit distance: ་, །\n",
    "output_df['edit_distance'] = output_df.apply(lambda row: editdistance.eval(row['gt'].replace('་', '').replace('།', ''), row['pred'].replace('་', '').replace('།', '')), axis=1)\n",
    "output_df.to_csv('./output_with_edit_distance_no_diacritics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245790/245790 [00:35<00:00, 6839.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without symbols: tsek and shey\n",
      "Total samples:  245790\n",
      "Accuracy:  0.89003620977257\n",
      "1 - NED:  0.9969187756614225\n",
      "Confidence:  0.8958869955094385\n",
      "Label Length:  57.43771512266569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate these values:, Accuracy, 1 - NED, Confidence, Label Length\n",
    "no_diacritics_df = pd.read_csv('./output_with_edit_distance_no_diacritics.csv')\n",
    "total_acc = 0\n",
    "total_ned = 0\n",
    "total_conf = 0\n",
    "total_label_len = 0\n",
    "for i in tqdm(range(len(no_diacritics_df))):\n",
    "    gt, pred = no_diacritics_df.iloc[i]['gt'], output_df.iloc[i]['pred']\n",
    "    if gt.replace('་', '').replace('།', '') == pred.replace('་', '').replace('།', ''):\n",
    "        total_acc += 1     \n",
    "    total_ned += 1 - no_diacritics_df.iloc[i]['edit_distance'] / max(len(gt), len(pred))\n",
    "    total_conf += no_diacritics_df.iloc[i]['confidence']\n",
    "    total_label_len += len(gt)\n",
    "    \n",
    "print('Results without symbols: tsek and shey')\n",
    "print('Total samples: ', len(no_diacritics_df))\n",
    "print('Accuracy: ', total_acc / len(output_df))\n",
    "print('1 - NED: ', total_ned / len(output_df))\n",
    "print('Confidence: ', total_conf / len(output_df))\n",
    "print('Label Length: ', total_label_len / len(output_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ord() expected string of length 1, but tuple found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m insertions \u001b[38;5;241m=\u001b[39m {k: (v, \u001b[38;5;28mord\u001b[39m(k)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m insertions\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      8\u001b[0m deletions \u001b[38;5;241m=\u001b[39m {k: (v, \u001b[38;5;28mord\u001b[39m(k)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m deletions\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 9\u001b[0m replacements \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreplacements\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m insertions \u001b[38;5;241m=\u001b[39m {k: (v, \u001b[38;5;28mord\u001b[39m(k)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m insertions\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      8\u001b[0m deletions \u001b[38;5;241m=\u001b[39m {k: (v, \u001b[38;5;28mord\u001b[39m(k)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m deletions\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 9\u001b[0m replacements \u001b[38;5;241m=\u001b[39m {k: (v, \u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m replacements\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mTypeError\u001b[0m: ord() expected string of length 1, but tuple found"
     ]
    }
   ],
   "source": [
    "# sort dictionaries with value\n",
    "insertions = dict(sorted(insertions.items(), key=lambda item: item[1], reverse=True))\n",
    "deletions = dict(sorted(deletions.items(), key=lambda item: item[1], reverse=True))\n",
    "replacements = dict(sorted(replacements.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# update value with (value, unicode(key))\n",
    "insertions_new = {k: (v, ord(k)) for k, v in insertions.items()}\n",
    "deletions = {k: (v, ord(k)) for k, v in deletions.items()}\n",
    "replacements = {k: (v, ord(k)) for k, v in replacements.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('་', (40211, 3851)), ('།', (5468, 3853)), ('ུ', (1599, 3956)), ('ོ', (876, 3964)), ('ི', (621, 3954)), ('ྲ', (605, 4018)), ('ེ', (541, 3962)), ('ས', (392, 3942)), ('ྱ', (387, 4017)), ('ཱ', (370, 3953))]\n",
      "[('་', (237, 3851)), ('།', (173, 3853)), ('ུ', (70, 3956)), ('ོ', (62, 3964)), ('ས', (61, 3942)), ('ེ', (60, 3962)), ('ི', (50, 3954)), ('ད', (45, 3921)), ('ག', (42, 3906)), ('ྲ', (38, 4018))]\n",
      "[(('༌', '་'), 9668), (('་', '༌'), 3327), (('༑', '།'), 2491), (('།', '་'), 1025), (('་', '།'), 476), (('།', '༑'), 406), (('ཪ', 'ར'), 292), (('ེ', 'ི'), 257), (('ི', 'ེ'), 231), (('༎', '།'), 210)]\n"
     ]
    }
   ],
   "source": [
    "# get top 10 \n",
    "print(list(insertions.items())[:10])\n",
    "print(list(deletions.items())[:10])\n",
    "print(list(replacements.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3946\n"
     ]
    }
   ],
   "source": [
    "print(ord('ཪ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insertions:\n",
      "༠ 0\n",
      "༡ 0\n",
      "༢ 0\n",
      "༣ 0\n",
      "༤ 0\n",
      "༥ 0\n",
      "༦ 0\n",
      "༧ 0\n",
      "༨ 0\n",
      "༩ 0\n",
      "༪ 0\n",
      "༫ 0\n",
      "༬ 0\n",
      "༭ 0\n",
      "༮ 0\n",
      "༯ 0\n",
      "༰ 0\n",
      "༱ 0\n",
      "༲ 0\n",
      "deletions:\n",
      "༠ 0\n",
      "༡ 0\n",
      "༢ 0\n",
      "༣ 0\n",
      "༤ 0\n",
      "༥ 0\n",
      "༦ 0\n",
      "༧ 0\n",
      "༨ 0\n",
      "༩ 0\n",
      "༪ 0\n",
      "༫ 0\n",
      "༬ 0\n",
      "༭ 0\n",
      "༮ 0\n",
      "༯ 0\n",
      "༰ 0\n",
      "༱ 0\n",
      "༲ 0\n",
      "replacements:\n",
      "༠ 0\n",
      "༡ 0\n",
      "༢ 0\n",
      "༣ 0\n",
      "༤ 0\n",
      "༥ 0\n",
      "༦ 0\n",
      "༧ 0\n",
      "༨ 0\n",
      "༩ 0\n",
      "༪ 0\n",
      "༫ 0\n",
      "༬ 0\n",
      "༭ 0\n",
      "༮ 0\n",
      "༯ 0\n",
      "༰ 0\n",
      "༱ 0\n",
      "༲ 0\n"
     ]
    }
   ],
   "source": [
    "# print dict values for Tibetan numerals\n",
    "tib_numerals = [chr(i) for i in range(0x0F20, 0x0F33)]\n",
    "print('insertions:')\n",
    "for num in tib_numerals:\n",
    "    print(num, insertions.get(num, 0))\n",
    "print('deletions:')\n",
    "for num in tib_numerals:    \n",
    "    print(num, deletions.get(num, 0))\n",
    "print('replacements:')\n",
    "for num in tib_numerals:\n",
    "    print(num, replacements.get(num, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
